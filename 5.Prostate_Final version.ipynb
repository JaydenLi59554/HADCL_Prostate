{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder,LabelEncoder,StandardScaler,MinMaxScaler\n",
    "from sksurv.datasets import load_gbsg2\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.ensemble import ComponentwiseGradientBoostingSurvivalAnalysis\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import math\n",
    "from datetime import datetime\n",
    "from sksurv.svm import FastSurvivalSVM\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.model_selection import ShuffleSplit,GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "from sklearn.metrics import precision_score, auc, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lifelines.utils import median_survival_times\n",
    "from lifelines.utils import survival_table_from_events\n",
    "from lifelines import KaplanMeierFitter \n",
    "import time\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.linear_model import Lasso,LassoLarsIC\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis,CoxnetSurvivalAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "from pycox.models import CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "import torchtuples as tt\n",
    "from scipy.stats import randint \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d02727",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_imputed.to_csv('5.Prostate.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcbfc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReusableUtils import ReusableUtils\n",
    "utils = ReusableUtils()\n",
    "utils.setNotebookConfigParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b59bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_info_columns',500)\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75efef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prostate = pd.read_csv('Prostate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4263fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prostate.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6db73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prostate.drop(columns=['pad_flag','ckd_cd','short_desc','dialysis_flag'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff48c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['time', 'status', 'sex','diagnosis_Age','bmi','central_obesity_flag', 'smoke_status_cd','alcohol_status_cd', \n",
    "             'dm_period','family_dm_flag', 'chd_flag', 'stroke_flag', 'ht_flag',\n",
    "             'insulin_flag', 'anti_htn_flag', 'anti_lipid_flag','diabetic_drug', \n",
    "             'hba1c', 'fasting_gc', 'total_clt', 'ldl_c', 'hdl_c','triglyceride', 'serum_k', 'creatinine']\n",
    "df_prostate = df_prostate[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prostate_dummy = pd.get_dummies(df_prostate,drop_first=True)# drop_first=True表示丢弃第一个类别，使之信息不冗余\n",
    "display(df_prostate_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e488ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失数据填补\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)# KNN全称: k nearest neighbor（K近邻算法）\n",
    "imputer.fit(df_prostate_dummy)# 拟合\n",
    "raw_imputed = imputer.transform(df_prostate_dummy)# 变换\n",
    "# 将填补后的协变量（数据格式）转为dataframe格式：\n",
    "raw_imputed = pd.DataFrame(columns=df_prostate_dummy.columns, data=raw_imputed)\n",
    "display(raw_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_prostate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c26f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prostate.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a282c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, chi2_contingency\n",
    "# Assuming your data is stored in a pandas DataFrame called 'data'\n",
    "\n",
    "# Step 1: Perform train-test split (70% train, 30% test)\n",
    "train_ratio = 0.7\n",
    "train_size = int(train_ratio * len(data))\n",
    "train_data = data.sample(train_size, random_state=42)\n",
    "test_data = data.drop(train_data.index)\n",
    "\n",
    "# Step 2: Calculate statistics for each feature\n",
    "result_data = pd.DataFrame(columns=['Feature', 'Train Value', 'Test Value'])\n",
    "target = 'status'\n",
    "\n",
    "for column in data.columns[1:-1]:\n",
    "    # For numerical features, calculate mean and standard deviation\n",
    "    if np.issubdtype(data[column].dtype, np.number):\n",
    "        train_mean = train_data[column].mean()\n",
    "        train_std = train_data[column].std()\n",
    "        test_mean = test_data[column].mean()\n",
    "        test_std = test_data[column].std()\n",
    "        result_data = result_data.append({\n",
    "            'Feature': column,\n",
    "            'Train Value': f'Mean ± Std: {train_mean:.2f} ± {train_std:.2f}',\n",
    "            'Test Value': f'Mean ± Std: {test_mean:.2f} ± {test_std:.2f}'\n",
    "        }, ignore_index=True)\n",
    "    # For categorical features, calculate value counts as percentages\n",
    "    else:\n",
    "        train_counts = train_data[column].value_counts(normalize=True) * 100\n",
    "        test_counts = test_data[column].value_counts(normalize=True) * 100\n",
    "        train_values_str = \"\\n \".join([f'{value}: {train_data[column].value_counts()[value]} ({train_percent:.2f}%)' for value, train_percent in train_counts.iteritems()])\n",
    "        test_values_str = \"\\n \".join([f'{value}: {test_data[column].value_counts().get(value, 0)} ({test_percent:.2f}%)' for value, test_percent in test_counts.iteritems()])\n",
    "        result_data = result_data.append({\n",
    "            'Feature': column,\n",
    "            'Train Value': train_values_str,\n",
    "            'Test Value': test_values_str\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 自动检查并标签编码所有的类别特征\n",
    "data_encoded = data.copy()\n",
    "cols = data_encoded.columns[1:-1]\n",
    "for column in cols:\n",
    "    if data_encoded[column].dtype == 'object':\n",
    "        label_encoder = LabelEncoder()\n",
    "        data_encoded[column] = label_encoder.fit_transform(data_encoded[column])\n",
    "\n",
    "# 计算所有特征与目标变量之间的Pearson相关系数\n",
    "correlations = data_encoded[cols].corrwith(data_encoded[target], method='spearman').rename(\"P\").abs().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4aceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_plot(data,need_corr=True,name='',title=''):\n",
    "\tplt.subplots(figsize = (30,20))\n",
    "\tsns.heatmap(data.corr(method='pearson') if need_corr else data, \n",
    "\t\t\t\tannot=True,\n",
    "\t\t\t\tcmap = 'RdBu',#色盘，可以理解为配色主题(在这里用Palette参数会报错)\n",
    "\t\t\t\tlinewidths = 0.1,#热力矩阵之间的线宽\n",
    "\t\t\t\tlinecolor='white',\n",
    "\t\t\t\tvmax = 0.9,#vmax,vmin, 图例(热力bar)中最大值和最小值的显示值，没有该参数时默认不显示\n",
    "\t\t\t\tsquare=False\n",
    "\t\t\t\t)\n",
    "# \tplt.title(title if name==None else title+name,fontsize = 20)\n",
    "\tplt.tight_layout()\n",
    "\tplt.savefig('Kid_correlation.pdf')\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "# data是dataframe类型\n",
    "corr_plot(data_encoded[data_encoded.columns[3:]],title = 'Feature Correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f43eae",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f27127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_prostate.drop(columns=['time','status'])\n",
    "X_dummy = pd.get_dummies(X,drop_first=True)\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputer.fit(X_dummy)\n",
    "X_imputed = imputer.transform(X_dummy)\n",
    "X_imputed = pd.DataFrame(columns=X_dummy.columns, data=X_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46bc8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = raw_imputed.loc[:,['status','time']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47916b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.util import Surv\n",
    "# 训练集\n",
    "y_train_ = Surv.from_dataframe(\n",
    "    event='event', \n",
    "    time='time', \n",
    "    data=y_train.rename(columns={'status':'event','malignant_surviving_month':'time'}))\n",
    "y_train_\n",
    "# 测试集\n",
    "y_test_ = Surv.from_dataframe(\n",
    "    event='event', \n",
    "    time='time', \n",
    "    data=y_test.rename(columns={'status':'event','malignant_surviving_month':'time'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a8092e",
   "metadata": {},
   "source": [
    "## CoxPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef9886",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = raw_imputed.columns[2:]\n",
    "summary_results = pd.DataFrame()\n",
    "# 循环对每个类别特征进行单因素COX回归分析\n",
    "for feature in features:\n",
    "    \n",
    "    cph = CoxPHFitter()\n",
    "\n",
    "    # 进行单因素COX回归分析\n",
    "    cph.fit(raw_imputed[[feature,'time', 'status']], duration_col='time', event_col='status')\n",
    "\n",
    "    # 提取结果并添加到汇总表\n",
    "    result = cph.summary.reset_index()\n",
    "    result['Feature'] = feature\n",
    "    summary_results = pd.concat([summary_results, result])\n",
    "\n",
    "# 重置索引并重命名列名\n",
    "summary_results.reset_index(drop=True, inplace=True)\n",
    "# summary_results.columns = ['Feature', 'Hazard Ratio', '95% CI (Lower)', '95% CI (Upper)', 'P-value']\n",
    "\n",
    "# 输出汇总表\n",
    "results1 = summary_results[['covariate','exp(coef)','exp(coef) lower 95%', 'exp(coef) upper 95%', 'p']].copy()\n",
    "results1.columns = ['Variables','HR2','exp(coef) lower 95%', 'exp(coef) upper 95%', 'P_value']\n",
    "results1['95% CI'] = results1['exp(coef) lower 95%'].map(lambda x:f'{x:.2f}') +', '+ results1['exp(coef) upper 95%'].map(lambda x:f'{x:.2f}')\n",
    "results1.drop(columns=['exp(coef) lower 95%', 'exp(coef) upper 95%'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建CoxPHFitter对象\n",
    "cph = CoxPHFitter()\n",
    "\n",
    "# 进行单因素COX回归分析\n",
    "cph.fit(raw_imputed[raw_imputed.columns[0:]], duration_col='time', event_col='status')\n",
    "\n",
    "# 提取结果\n",
    "results2 = cph.summary.reset_index()[['covariate','exp(coef)','exp(coef) lower 95%', 'exp(coef) upper 95%', 'p']].rename(columns={'p':'P_value'})\n",
    "results2.columns = ['Variables','HR2','exp(coef) lower 95%', 'exp(coef) upper 95%', 'P_value']\n",
    "results2['95% CI'] = results2['exp(coef) lower 95%'].map(lambda x:f'{x:.2f}') +', '+ results2['exp(coef) upper 95%'].map(lambda x:f'{x:.2f}')\n",
    "results2.drop(columns=['exp(coef) lower 95%', 'exp(coef) upper 95%'],inplace=True)\n",
    "results_cox = pd.merge(results1,results2,on='Variables',suffixes=['_Univariate Cox','_Multivariate Cox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e0292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "\n",
    "cox = CoxPHSurvivalAnalysis()\n",
    "cox.fit(X_train, y_train_)# 模型拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb79cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "y_pred = cox.predict(X_train)\n",
    "result = concordance_index_censored(y_train_['event'], y_train_['time'], y_pred)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa841ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "y_pred = cox.predict(X_test)\n",
    "result = concordance_index_censored(y_test_['event'], y_test_['time'], y_pred)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fae672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "\n",
    "times = np.arange( y_test_['time'].min(),y_test_['time'].max() )\n",
    "chfs = cox.predict_cumulative_hazard_function(X_test)\n",
    "#preds = np.asarray([[fn(t) for t in times] for fn in chfs])\n",
    "preds = cox.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tcauc cph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "preds = cox.predict(X_test)\n",
    "aucs_cph, mean_auc_cph = cumulative_dynamic_auc(y_train_, y_test_, preds, times)\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "# aucs curve\n",
    "plt.plot(times,aucs_cph)\n",
    "# mean auc\n",
    "plt.axhline(y=mean_auc_cph, color='black', ls ='--')\n",
    "ax.annotate('mean auc CoxPH={:.3f}'.format(mean_auc_cph), xy=(100,mean_auc_cph), xytext=(200,mean_auc_cph+0.01), fontsize=10)\n",
    "\n",
    "plt.xlabel('time(month)')\n",
    "plt.ylabel('auc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cph = shap.Explainer(cox.predict,X_train)\n",
    "shap_values_cph = exp_cph(X_test)\n",
    "#shap.plots.beeswarm(shap_values,max_display=44)\n",
    "shap.summary_plot(shap_values_cph,X_test,max_display=44,plot_size=(12,20),show=False)\n",
    "plt.savefig('coxph_shap_pro.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# help(cph.plot)\n",
    "fig,ax = plt.subplots(figsize=(4,6))#dpi=120\n",
    "#plt.title('Forest graph -- ')\n",
    "cph.plot(ax=ax,hazard_ratios=True)# 森林图\n",
    "#cph.plot(ax=ax)\n",
    "ax.grid(color='grey',ls='--')#网格\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.savefig('Forest_graph_Col.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c8fa93",
   "metadata": {},
   "source": [
    "## Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b75095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.tree import SurvivalTree\n",
    "tree = SurvivalTree(max_depth=20, min_samples_leaf=5, min_samples_split=3)\n",
    "\n",
    "#time setting\n",
    "lower,upper = np.percentile(y['time'],[10,90])\n",
    "times = np.arange(lower,upper + 1)\n",
    "from sksurv.tree import SurvivalTree\n",
    "tree = SurvivalTree(max_depth=2, min_samples_leaf=2, min_samples_split=3)\n",
    "#gcv\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# 实例化一个网格搜索器\n",
    "# # 方式1：\n",
    "parameters = {\n",
    "    'max_depth':[2, 10, 20],\n",
    "    'min_samples_split':[3,6,9], \n",
    "    'min_samples_leaf':[2,3,4,5],\n",
    "}# 字典，超参数及其可能的取值\n",
    "gscv = GridSearchCV(tree, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a386f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start training...\")\n",
    "start_time = time.time()\n",
    "#Search\n",
    "gscv.fit(X_train, y_train_)# 在训练集上寻优\n",
    "print(f'---{round(time.time()-start_time,3)}seconds ---')\n",
    "display(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SurvivalTree(max_depth=10, min_samples_leaf=2, min_samples_split=9)\n",
    "tree.fit(X_train, y_train_)\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "y_pred = tree.predict(X_train)\n",
    "result = concordance_index_censored(y_train_['event'], y_train_['time'], y_pred)\n",
    "display(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd93e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "result = concordance_index_censored(y_test_['event'], y_test_['time'], y_pred)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = shap.Explainer(tree.predict,X_train)\n",
    "shap_values = exp(X_test)\n",
    "shap.plots.beeswarm(shap_values,max_display=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tree = shap.Explainer(tree.predict,X_train)\n",
    "shap_values_tree = exp_tree(X_test)\n",
    "shap.summary_plot(shap_values_tree,X_test,max_display=44,plot_size=(12,20),show=False)\n",
    "plt.savefig('tree_shap_prostate.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9212d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "\n",
    "times = np.arange( y_test_['time'].min(),y_test_['time'].max() )\n",
    "treesurv = tree.predict_cumulative_hazard_function(X_test)\n",
    "preds = np.asarray([[fn(t) for t in times] for fn in treesurv])\n",
    "aucs_tree, mean_auc_tree = cumulative_dynamic_auc(y_train_, y_test_, preds, times)\n",
    "aucs_tree = np.nan_to_num(aucs_tree,nan=0)\n",
    "mean_auc_tree = np.mean(aucs_tree)\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "# aucs curve\n",
    "plt.plot(times,aucs_tree)\n",
    "# mean auc\n",
    "plt.axhline(y=mean_auc_tree, color='black', ls ='--')\n",
    "ax.annotate('Decision Tree mean auc={:.3f}'.format(mean_auc_tree), xy=(100,mean_auc_tree), xytext=(150,mean_auc_tree+0.01), fontsize=10)\n",
    "\n",
    "plt.xlabel('time(month)')\n",
    "plt.ylabel('auc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29f817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db82da85",
   "metadata": {},
   "source": [
    "## RSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "rsf = RandomSurvivalForest(n_estimators=100,\n",
    "                           min_samples_split=10,\n",
    "                           min_samples_leaf=15,\n",
    "                           max_features=\"sqrt\",\n",
    "                           n_jobs=-1,\n",
    "                           random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start training...\")\n",
    "start_time = time.time()\n",
    "rsf.fit(X_train, y_train_)\n",
    "print(f'---{round(time.time()-start_time,3)}seconds ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "y_pred = rsf.predict(X_train)\n",
    "result = concordance_index_censored(y_train_['event'], y_train_['time'], y_pred)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698be5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "y_pred = rsf.predict(X_test)\n",
    "result = concordance_index_censored(y_test_['event'], y_test_['time'], y_pred)\n",
    "display(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "\n",
    "times = np.arange( y_test_['time'].min(),y_test_['time'].max() )\n",
    "rsfsurv = rsf.predict_cumulative_hazard_function(X_test)\n",
    "preds = np.asarray([[fn(t) for t in times] for fn in rsfsurv])\n",
    "aucs_rsf, mean_auc_rsf = cumulative_dynamic_auc(y_train_, y_test_, preds, times)\n",
    "aucs_rsf = np.nan_to_num(aucs_rsf,nan=0)\n",
    "mean_auc_rsf = np.mean(aucs_rsf)\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "# aucs curve\n",
    "plt.plot(times,aucs_rsf)\n",
    "# mean auc\n",
    "plt.axhline(y=mean_auc_rsf, color='black', ls ='--')\n",
    "ax.annotate('RSF mean auc={:.3f}'.format(mean_auc_rsf), xy=(100,mean_auc_rsf), xytext=(150,mean_auc_rsf+0.01), fontsize=10)\n",
    "\n",
    "plt.xlabel('time(month)')\n",
    "plt.ylabel('auc')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8917c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_rsf = shap.Explainer(rsf.predict,X_train)\n",
    "shap_values_rsf = exp_rsf(X_test)\n",
    "#shap.plots.beeswarm(shap_values_rsf,max_display=44)\n",
    "shap.summary_plot(shap_values_rsf,X_test,max_display=44,plot_size=(12,20),show=False)\n",
    "plt.savefig('rsf_shap_pro.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacdafa3",
   "metadata": {},
   "source": [
    "## Coxboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d96f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc2788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "coxboost =  GradientBoostingSurvivalAnalysis(loss=\"coxph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "coxboost.fit(X_train, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "y_pred = coxboost.predict(X_train)\n",
    "result = concordance_index_censored(y_train_['event'], y_train_['time'], y_pred)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa93605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "y_pred = coxboost.predict(X_test)\n",
    "result = concordance_index_censored(y_test_['event'], y_test_['time'], y_pred)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "\n",
    "times = np.arange( y_test_['time'].min(),y_test_['time'].max() )\n",
    "coxboostsurv = coxboost.predict_cumulative_hazard_function(X_test)\n",
    "#preds = np.asarray([[fn(t) for t in times] for fn in coxboostsurv])\n",
    "preds = y_pred\n",
    "aucs_coxboost, mean_auc_coxboost = cumulative_dynamic_auc(y_train_, y_test_, preds, times)\n",
    "aucs_coxboost = np.nan_to_num(aucs_coxboost,nan=0)\n",
    "mean_auc_coxboost = np.mean(aucs_coxboost)\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "# aucs curve\n",
    "plt.plot(times,aucs_coxboost)\n",
    "# mean auc\n",
    "plt.axhline(y=mean_auc_coxboost, color='black', ls ='--')\n",
    "ax.annotate('Coxboost mean auc={:.3f}'.format(mean_auc_coxboost), xy=(100,mean_auc_coxboost), xytext=(150,mean_auc_coxboost+0.01), fontsize=10)\n",
    "\n",
    "plt.xlabel('time(month)')\n",
    "plt.ylabel('auc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0779ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = shap.Explainer(coxboost.predict,X_train)\n",
    "shap_values = exp(X_test)\n",
    "shap.plots.beeswarm(shap_values,max_display=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de143ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_coxboost = shap.Explainer(coxboost.predict,X_train)\n",
    "shap_values_coxboost = exp_coxboost(X_test)\n",
    "#shap.plots.beeswarm(shap_values_rsf,max_display=44)\n",
    "shap.summary_plot(shap_values_coxboost,X_test,max_display=44,plot_size=(12,20),show=False)\n",
    "plt.savefig('coxboost_shap_pro.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805701c8",
   "metadata": {},
   "source": [
    "## Coxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d956f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cox_lasso = CoxnetSurvivalAnalysis(l1_ratio = 1.0,alpha_min_ratio = 0.01,fit_baseline_model=True)\n",
    "cox_lasso.fit(X_train, y_train_)\n",
    "cindex_train = cox_lasso.score(X_train, y_train_)\n",
    "print(round(cindex_train,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cindex_test = cox_lasso.score(X_test,y_test_)\n",
    "print(round(cindex_test,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399a7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "\n",
    "times = np.arange( y_test_['time'].min(),y_test_['time'].max() )\n",
    "cox_lassosurv = cox_lasso.predict_cumulative_hazard_function(X_test)\n",
    "#preds = np.asarray([[fn(t) for t in times] for fn in cox_lassosurv])\n",
    "preds = cox_lasso.predict(X_test)\n",
    "aucs_coxnet, mean_auc_coxnet = cumulative_dynamic_auc(y_train_, y_test_, preds, times)\n",
    "aucs_coxnet = np.nan_to_num(aucs_coxnet,nan=0)\n",
    "mean_auc_coxnet = np.mean(aucs_coxnet)\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "# aucs curve\n",
    "plt.plot(times,aucs_coxnet)\n",
    "# mean auc\n",
    "plt.axhline(y=mean_auc_coxnet, color='black')\n",
    "ax.annotate('Coxnet mean auc={:.3f}'.format(mean_auc_coxnet), xy=(100,mean_auc_coxnet), xytext=(150,mean_auc_coxnet+0.01), fontsize=10)\n",
    "#ax.annotate('Decision Tree mean auc={:.3f}'.format(mean_auc_tree), xy=(100,mean_auc_tree), xytext=(150,mean_auc_tree+0.01), fontsize=10)\n",
    "plt.xlabel('time(month)')\n",
    "plt.ylabel('auc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a352ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = shap.Explainer(cox_lasso.predict,X_train)\n",
    "shap_values = exp(X_test)\n",
    "shap.plots.beeswarm(shap_values,max_display=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efece847",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_coxnet = shap.Explainer(cox_lasso.predict,X_train)\n",
    "shap_values_coxnet = exp_coxnet(X_test)\n",
    "#shap.plots.beeswarm(shap_values_rsf,max_display=44)\n",
    "shap.summary_plot(shap_values_coxnet,X_test,max_display=44,plot_size=(12,20),show=False)\n",
    "plt.savefig('coxnet_shap_pro.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ba934e",
   "metadata": {},
   "source": [
    "## tc-auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916b3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(0.38,1)\n",
    "\n",
    "\n",
    "plt.plot(times, aucs_coxboost, \"-\", label=f\"CoxBoost (mean AUC = {mean_auc_coxboost:.3f})\",color = \"#551F33\")\n",
    "plt.plot(times, aucs_coxnet, \"-\", label=f\"CoxNet (mean AUC = {mean_auc_coxnet:.3f})\",color = \"#F5E4C8\")\n",
    "plt.plot(times, aucs_rsf, \"-\", label=f\"RSF (mean AUC = {mean_auc_rsf:.3f})\",color = \"#BD4146\")\n",
    "plt.plot(times, aucs_cph, \"-\", label=f\"CoxPH (mean AUC = {mean_auc_cph:.3f})\",color = \"#ECC68C\")\n",
    "plt.plot(times, aucs_tree, \"-\", label=f\"Survival Tree (mean AUC = {mean_auc_tree:.3f})\",color = \"#CBBBC1\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"Time(Months)\",fontsize=12)\n",
    "plt.ylabel(\"Time-dependent AUC\",fontsize=12)\n",
    "plt.legend(loc=\"lower right\",fontsize=8)\n",
    "plt.grid(True)\n",
    "plt.savefig('Time_dependent_auc_Prostate.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f3704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
